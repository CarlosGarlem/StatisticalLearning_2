{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BackPropagation\n",
    "Carlos Garcia - 21000475"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xJPhEzbqWp9"
   },
   "source": [
    "<img src=\"./imgs/red.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1628129715157,
     "user": {
      "displayName": "Luis Fernando Leal Hernandez",
      "photoUrl": "",
      "userId": "08643725771405988586"
     },
     "user_tz": 300
    },
    "id": "Q1yAwOc4qPLs"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[3, 10]], dtype = 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3 = np.array([\n",
    "               [-0.23, 0.22, 0.77],\n",
    "               [0.9, 0.88, -0.4]\n",
    "            ])\n",
    "\n",
    "\n",
    "h2 = np.array([\n",
    "               [-0.3, 0.62, 0.45],\n",
    "               [0.45, 0.57, 0.48],\n",
    "               [0.65, 0.58, -0.45]\n",
    "            ])\n",
    "\n",
    "h1 = np.array([\n",
    "               [0.3, 0.46, 0.02],\n",
    "               [0.22, -0.7, 0.65],\n",
    "               [0.65, 0.9, 0.34]\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_h3 = np.matmul(x, h3)\n",
    "delta_h2 = np.matmul(delta_h3, h2)\n",
    "delta_h1 = np.matmul(delta_h2, h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hidden Layer 3 ---------------\n",
      "[[ 8.31  9.46 -1.69]]\n",
      "Neuron with most error is: 2\n",
      "\n",
      "Hidden Layer 2 ---------------\n",
      "[[0.6655 9.5642 9.0408]]\n",
      "Neuron with most error is: 2\n",
      "\n",
      "Hidden Layer 1 ---------------\n",
      "[[8.180294 1.74791  9.303912]]\n",
      "Neuron with most error is: 3\n"
     ]
    }
   ],
   "source": [
    "layers = [delta_h3, delta_h2, delta_h1]\n",
    "i = 3\n",
    "for layer in layers:\n",
    "    n = np.argmax(layer.flatten())\n",
    "    print('\\nHidden Layer {} ---------------'.format(i))\n",
    "    print(layer)\n",
    "    print('Neuron with most error is: {}'.format(n+1))\n",
    "    i -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR con ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.where(x > 0.0, x, 0.0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_bias(x):\n",
    "    return np.hstack((x, np.ones((x.shape[0], 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(input_features, layers):\n",
    "    #layers contain the number of layers neurons and is equal to the length of hidden + output layers\n",
    "    weights = dict()\n",
    "    bias = 1\n",
    "    neurons = input_features + bias\n",
    "    for l in range(1, len(layers) + 1):\n",
    "        weights['W{}'.format(l)] = np.random.normal(loc = 0, scale = 0.1, size = (neurons, layers[l-1]))\n",
    "        neurons = layers[l-1] + bias        \n",
    "        \n",
    "    return weights    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 0.]]\n",
      "(4, 2)\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 1],\n",
    "              [1, 0],\n",
    "              [0, 1],\n",
    "              [0, 0]], dtype = 'float')\n",
    "\n",
    "y = np.array([0,1,1,0]).reshape(4,1)\n",
    "\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[-0.10507131, -0.18016528],\n",
       "        [-0.10829563,  0.0695341 ],\n",
       "        [ 0.11081245, -0.05081181]]),\n",
       " 'W2': array([[-0.23582609, -0.19435048],\n",
       "        [ 0.03061882,  0.04692732],\n",
       "        [ 0.09114026,  0.01024636]]),\n",
       " 'W3': array([[-0.02746457],\n",
       "        [ 0.03515202],\n",
       "        [-0.01518075]])}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = initialize_weights(x.shape[1], [2,2,1])\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(x, weights):\n",
    "    \n",
    "    layer = append_bias(x)\n",
    "    num_layers = len(weights.keys())\n",
    "    for l in range(1, num_layers):\n",
    "        Z = np.matmul(layer, weights['W{}'.format(l)])\n",
    "        A = relu(Z)\n",
    "        layer = append_bias(A)\n",
    "        \n",
    "    Z = np.matmul(layer, weights['W{}'.format(num_layers)])\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01732369],\n",
       "       [-0.01732573],\n",
       "       [-0.01730945],\n",
       "       [-0.01696616]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = forward_propagation(x, weights)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCost(y_hat, y_real):\n",
    "    return 1/2 * np.mean(np.power(y_hat - y_real, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2588072649626528"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getCost(results, y)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM4mu7/uuh9fHS0M6siTuFJ",
   "collapsed_sections": [],
   "name": "forward_propagation_numpy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
